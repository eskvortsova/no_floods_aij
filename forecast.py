# -*- coding: utf-8 -*-
"""predict.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1E0ureRxlyArt6PBeXzBu4o_iIsKiz9Fg

## Предсказание уровней воды на реке Амур
"""

# импортируем все необходимые библиотеки
import pandas as pd
import numpy as np
import seaborn as sns
import lightgbm as lgb
import shap
import argparse
import pickle
from catboost import CatboostRegressor
from datetime import datetime, timedelta
from sklearn.tree import DecisionTreeRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, mean_squared_error

parser = argparse.ArgumentParser()
parser.add_argument("f_day", type=str)
parser.add_argument("l_day", type=str)
p = parser.parse_args()
f_day = pd.to_datetime(p.f_day)
l_day = pd.to_datetime(p.l_day)
predict_ndays = (l_day - f_day).days


# Путь до папки с данными
path_to_data = 'datasets/'

daily = pd.read_pickle(path_to_data + 'processed_data/daily.pkl')

daily = daily.sort_values(by=['station_id','date'])
daily = daily.reset_index(drop=True)

# Выбираем целевые гидрологические посты
station_ids = [6005, 6022, 6296, 6027, 5004, 5012, 5024, 5805]
daily = daily[daily['station_id'].isin(station_ids)]

nf = pd.read_csv(path_to_data + 'hydro_2018-2020/new_data_target.csv', sep=';')

nf['time'] = pd.to_datetime(nf['time'], format='%Y-%m-%d %H:%M:%S')
nf.columns = ['date', 'stage_max', 'station_id']
nf = nf.sort_values(by=['station_id', 'date'])
nf = nf.set_index('date')
nf = nf[nf.index > '2017-12-31']

nf.loc[(nf['stage_max'] > nf['stage_max'].\
          quantile(0.99))&(nf['station_id'] == 5012), 'stage_max'] = np.nan

sf = nf[nf['station_id'] == 5012]


nf = nf.reset_index()
nf = nf.reindex(['date', 'stage_avg', 'stage_min', 'stage_max', 'temp', 'water_code',
       'station_id'], axis=1)
daily = pd.concat([daily, nf], axis=0)
daily = daily.sort_values(by=['station_id', 'date'])

s2m = pd.read_pickle(path_to_data + 'processed_data/s2m.pkl')

# Вспомогательная функция для соединения идентичных датафреймов 
def weary_append(x,y):
    if x is not None:
        if any([a for a in list(x.columns) if a not in y.columns]) or any([a for a in list(y.columns) if a not in x.columns]):
            raise ValueError()
        else:
            return x.append(y)
    else:
        return y

meteo = None
for s, m in s2m.loc[station_ids][['meteo_id']].iterrows():
    m = m.values[0]
    df = pd.read_csv(path_to_data + 'meteo/{}.csv'.format(m), sep=';').rename({'station_id': 
                                                                                        'meteo_id'}, axis=1)
    df['datetime'] = pd.to_datetime(df['time'], format='%Y-%m-%d %H:%M:%S')
    df['date'] = df['datetime'].apply(lambda x: x.date())
    df['station_id'] = s
    meteo = weary_append(meteo, df)

meteo.loc[meteo['date'] < datetime(1993,1,1).date(), 'datetime'] = \
    meteo.loc[meteo['date'] < datetime(1993,1,1).date(), 'datetime'].apply(lambda x: x - timedelta(hours=3))

meteo = meteo.set_index('datetime')
#meteo[meteo.index.month==3].groupby(meteo[meteo.index.month==3].index.hour)['temperature_air'].mean()

meteo['night'] = (meteo.index.hour > 14) | (meteo.index.hour < 2)
dmeteo = meteo.groupby(['station_id', 'date', 'night'])[['temperature_air', 
                                                    'temperature_ground']].mean().reset_index(level=2)
dmeteo = dmeteo.pivot(columns='night')
ncols = []
for col in dmeteo.columns:
    if col[1]:
        prefix = 'night_'
    else:
        prefix = 'day_'
    ncols.append(prefix + col[0])
dmeteo.columns = ncols

dmeteo[['humidity', 'precipitation_amount']] = \
meteo.groupby(['station_id', 'date'])[['humidity', 'precipitation_amount']].agg({'humidity': 'mean', 
                                                                                 'precipitation_amount': 'max'})

def agg_meteo(df, 
              columns = ['day_temperature_air', 'night_temperature_air', 'day_temperature_ground', 
                         'night_temperature_ground', 'humidity','precipitation_amount'],
              agg_days = [15, 15, 15, 15, 10, 60],
              agg_funcs = ['mean', 'mean', 'mean', 'mean', 'sum', 'sum'],
              shift = [10, 10, 10, 10, 10, 10]):
    res = pd.DataFrame(index=df.index)
    names = []
    for c, d, f, s in zip(columns, agg_days, agg_funcs, shift):
        name = '{}_{}_{}'.format(c, d, s)
        res[name] = df[c].rolling(d, min_periods=1).agg(f).shift(s)
        names.append('{}_{}_{}'.format(c, d, s))
    return res.reset_index(), names

agg, meteo_feats = agg_meteo(dmeteo)
agg['date'] = pd.to_datetime(agg['date'])

daily = daily.merge(agg, on=['station_id', 'date'], how='left')

daily = daily.set_index('date')
daily['year'] = daily.index.year
daily['month'] = daily.index.month
daily['day'] = daily.index.day
daily['doy'] = daily.index.dayofyear
daily = daily.reset_index()

def decision_tree_nan_filler(df, column, metric):
  """
  params: df - dataframe
  params: column - column with nans for value prediction
  params: criterion - mae,mse

  returns: y_hat - list of predicted values
  """

  X = df[df[column].notna()].fillna(df.mean()).drop(['date'], axis =1)
  y = X[column].to_list()
  X = X.drop([column], axis = 1)
  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)
  dtr = DecisionTreeRegressor(random_state=0, criterion = metric, max_depth = 7)
  dtr.fit(X_train, y_train)
  y_hat = dtr.predict(X_test)
  if metric == 'mae':
    print(metric, ' : ', mean_absolute_error(y_test, y_hat))
  elif metric == 'mse':
    print(metric, ' ; ', mean_squared_error(y_test, y_hat))
  y_hat = dtr.predict(df[df[column].isna()].fillna(df.mean()).drop(['date', column], axis =1))
  part_1 = df[df[column].notna()]
  part_2 = df[df[column].isna()]
  part_2[column] = y_hat
  final_df = pd.concat([part_1, part_2]).sort_values(['date'], ascending = True)
  return final_df

nan_columns_mae = ['stage_avg', 'stage_min']
nan_columns_mse = ['temp', 'day_temperature_air_15_10', 'night_temperature_air_15_10',
                   'day_temperature_ground_15_10', 'humidity_10_10',
                   'precipitation_amount_60_10','night_temperature_ground_15_10']

for col in nan_columns_mae:
  daily = decision_tree_nan_filler(daily, col, 'mae')

for col in nan_columns_mse:
  daily = decision_tree_nan_filler(daily, col, 'mse')

def add_years(d, years):
    try:
        return d.replace(year = d.year + years)
    except ValueError:
        return d + (datetime(d.year + years, 1, 1) - datetime(d.year, 1, 1))

past = []
for y in range(1, 6):
    daily['ndate'] = daily['date'].apply(lambda x: add_years(x, y))
    hf = daily[['ndate', 'station_id', 'stage_max']].rename({'ndate': 'date', 'stage_max': 
                                                             'past_{}'.format(y)}, axis=1)
    
    hf = hf.set_index(['station_id', 'date']) 
    hf = hf[~hf.index.duplicated(keep='first')]
    hf = hf.reset_index()
    
    daily = daily.merge(hf, on=['station_id', 'date'], how='left').drop('ndate', axis=1)

    for i in range(predict_ndays+1):
        daily['past_{}_{}'.format(y, i)] = daily['past_{}'.format(y)].shift(-i)
        past.append('past_{}_{}'.format(y, i))
    daily.drop('past_{}'.format(y), axis=1, inplace=True)

daily = daily.set_index(['station_id', 'date'])
new_index = pd.MultiIndex.from_product([daily.index.get_level_values(0).unique(), 
                                        pd.date_range('1984-1-1', '2020-10-01')])
daily = daily.reindex(new_index)

ndays = 20

daily['target'] = daily['stage_max']
ts = []
for i in range(ndays, 0, -1):
    daily['ts_{}'.format(i)] = daily.groupby('station_id')['stage_max'].shift(i)
    ts.append('ts_{}'.format(i))
# daily.drop('stage_max', axis=1, inplace=True)

daily = daily[daily['target'].notna()]

def steps_predict(model, ts_data, test_data, features, n):
    isfeat = len(features) > 0
    test_features = test_data[features].values
    if isfeat:
        data = np.r_[test_features[0], ts_data].reshape(1,-1)
    else:
        data = ts_data.reshape(1,-1)
    predict = []
    predict.append(model.predict(data)[0])

    for i in range(1, n):
        ts_data = np.r_[ts_data[1:], predict[i-1]]
        if isfeat:
            data = np.r_[test_features[i], ts_data].reshape(1,-1)
        else:
            data = ts_data.reshape(1,-1)
        predict.append(model.predict(data)[0])
    return np.array(predict)

def metrics(true, pred, station_id, printit=False):
    mae = np.mean(np.abs(pred - true))   
    if printit:
        print("MAE: {}".format(mae))
    return mae

def plot_predict(true, pred, station_id=None):
    plt.figure(figsize=(20, 5))
    plt.plot(true)
    plt.plot(pred)
    leg = ['true values', 'predict values']
    
    plt.legend(leg)
    if station_id is not None:
        plt.title(station_id)
    plt.show()

sample_submission = pd.DataFrame(index=pd.date_range(f_day, l_day - timedelta(1)))
for st_id in station_ids:
    station_id = st_id
    path_model = '/models'+str(station_id)+'_model.pkl'
    with open(path_model, 'rb') as f:
      model_cat = pickle.load(f)
      sf = daily.loc[int(key)]
      X_test = sf.loc[(sf.index >= f_day)&(sf.index < l_day), features]
      y_test = sf.loc[(sf.index >= f_day)&(sf.index < l_day), 'target']
      ts_data = y_train.values[-ndays:]
      predict = steps_predict(model_cat, ts_data, X_test, features, predict_ndays)
      sample_submission[st_id] = predict # запись результата в таблицу

sample_submission.to_csv('submission.csv')

print(sample_submission)